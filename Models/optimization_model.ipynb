{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers tensorflow requests matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# --------------------------------------\n",
    "# Amazon API Data Fetching\n",
    "# --------------------------------------\n",
    "def fetch_campaign_data(campaign_id, start_date, end_date, auth_token):\n",
    "    \"\"\"\n",
    "    Fetch data from Amazon Advertising API for a specific ad campaign.\n",
    "    \"\"\"\n",
    "    endpoint = f'https://advertising-api.amazon.com/v2/sp/campaigns/{campaign_id}/adGroups'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {auth_token}',\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    params = {\n",
    "        'startDate': start_date,\n",
    "        'endDate': end_date,\n",
    "    }\n",
    "    response = requests.get(endpoint, headers=headers, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# --------------------------------------\n",
    "# BERTweet Keyword Extraction\n",
    "# --------------------------------------\n",
    "def extract_keywords(customer_search_terms):\n",
    "    \"\"\"\n",
    "    Extract keywords using 'finiteautomata/bertweet-base-sentiment-analysis' model.\n",
    "    Only keep terms with positive or neutral sentiment.\n",
    "    \"\"\"\n",
    "    model = pipeline('sentiment-analysis', model='finiteautomata/bertweet-base-sentiment-analysis')\n",
    "    extracted_keywords = []\n",
    "    for term in customer_search_terms:\n",
    "        sentiment = model(term)[0]\n",
    "        # Keep only terms with positive or neutral sentiment\n",
    "        if sentiment['label'] in ['POS', 'NEU']:\n",
    "            extracted_keywords.append(term)\n",
    "    return extracted_keywords\n",
    "\n",
    "# --------------------------------------\n",
    "# CNN for Keyword Classification\n",
    "# --------------------------------------\n",
    "def build_cnn_model(input_shape):\n",
    "    \"\"\"\n",
    "    Build a CNN model for classifying keywords into profitable, non-profitable, and neutral.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv1D(32, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Conv1D(64, 3, activation='relu'))\n",
    "    model.add(layers.MaxPooling1D(2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))  # 3 output classes: Profitable, Non-profitable, Neutral\n",
    "    return model\n",
    "\n",
    "def classify_keywords_with_cnn(keywords, performance_data, cnn_model):\n",
    "    \"\"\"\n",
    "    Classify keywords using CNN into Profitable, Non-profitable, and Neutral categories.\n",
    "    \"\"\"\n",
    "    keyword_classifications = {}\n",
    "    for keyword in keywords:\n",
    "        features = np.array(performance_data[keyword])  # Get performance data for the keyword\n",
    "        features_reshaped = features.reshape((1, len(features), 1))  # Reshape for CNN input\n",
    "        \n",
    "        prediction = cnn_model.predict(features_reshaped)\n",
    "        class_label = ['Profitable', 'Non-profitable', 'Neutral'][prediction.argmax()]\n",
    "        keyword_classifications[keyword] = class_label\n",
    "    return keyword_classifications\n",
    "\n",
    "# --------------------------------------\n",
    "# Visual Representation (Pie Chart)\n",
    "# --------------------------------------\n",
    "def plot_pie_chart(profitable, non_profitable, neutral):\n",
    "    \"\"\"\n",
    "    Plot a pie chart of keyword classifications.\n",
    "    \"\"\"\n",
    "    labels = 'Profitable', 'Non-profitable', 'Neutral'\n",
    "    sizes = [len(profitable), len(non_profitable), len(neutral)]\n",
    "    \n",
    "    fig1, ax1 = plt.subplots()\n",
    "    ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "    ax1.axis('equal')  # Equal aspect ratio ensures the pie is drawn as a circle.\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# --------------------------------------\n",
    "# Main Pipeline for Fetching Data, Keyword Extraction, Classification, and Visualization\n",
    "# --------------------------------------\n",
    "def amazon_campaign_optimizer(campaign_id, start_date, end_date, auth_token):\n",
    "    \"\"\"\n",
    "    Complete workflow for optimizing an Amazon ad campaign.\n",
    "    - Fetches data via Amazon API\n",
    "    - Extracts keywords with BERTweet\n",
    "    - Classifies keywords using CNN model\n",
    "    - Visualizes results\n",
    "    \"\"\"\n",
    "    # 1. Fetch Campaign Data\n",
    "    campaign_data = fetch_campaign_data(campaign_id, start_date, end_date, auth_token)\n",
    "    \n",
    "    if not campaign_data:\n",
    "        return \"No data available.\"\n",
    "\n",
    "    # 2. Extract Keywords from Customer Search Terms\n",
    "    customer_search_terms = [ad['searchTerm'] for ad in campaign_data['adGroups']]  # Example extraction\n",
    "    extracted_keywords = extract_keywords(customer_search_terms)\n",
    "\n",
    "    # 3. Prepare Performance Data for Classification\n",
    "    # Simulate performance data (Clicks, CPC, etc.) for CNN input\n",
    "    performance_data = {\n",
    "        keyword: [np.random.randint(50, 500), np.random.uniform(0.5, 3.0), np.random.randint(100, 5000)] for keyword in extracted_keywords\n",
    "    }\n",
    "\n",
    "    # 4. Build and Train CNN Model\n",
    "    input_shape = (len(performance_data[extracted_keywords[0]]), 1)  # Define input shape based on performance data\n",
    "    cnn_model = build_cnn_model(input_shape)\n",
    "    \n",
    "    # Simulate training data (in practice, you'd need labeled data here)\n",
    "    X_train = np.array(list(performance_data.values()))\n",
    "    X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    y_train = tf.keras.utils.to_categorical(np.random.randint(3, size=(X_train.shape[0],)))  # Simulate labels\n",
    "    \n",
    "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    cnn_model.fit(X_train_reshaped, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "    # 5. Classify Extracted Keywords\n",
    "    classified_keywords = classify_keywords_with_cnn(extracted_keywords, performance_data, cnn_model)\n",
    "\n",
    "    # 6. Present Results\n",
    "    profitable = [k for k, v in classified_keywords.items() if v == 'Profitable']\n",
    "    non_profitable = [k for k, v in classified_keywords.items() if v == 'Non-profitable']\n",
    "    neutral = [k for k, v in classified_keywords.items() if v == 'Neutral']\n",
    "    \n",
    "    print(\"Profitable Keywords:\", profitable)\n",
    "    print(\"Non-profitable Keywords:\", non_profitable)\n",
    "    print(\"Neutral Keywords:\", neutral)\n",
    "\n",
    "    # 7. Visualize Classification Results\n",
    "    plot_pie_chart(profitable, non_profitable, neutral)\n",
    "\n",
    "# --------------------------------------\n",
    "# Example Usage\n",
    "# --------------------------------------\n",
    "campaign_id = '12345'\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-01-31'\n",
    "auth_token = 'YOUR_AUTH_TOKEN'\n",
    "\n",
    "amazon_campaign_optimizer(campaign_id, start_date, end_date, auth_token)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
